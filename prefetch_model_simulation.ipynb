{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c63ec10",
   "metadata": {},
   "source": [
    "\n",
    "# Predictive Prefetch Simulation (WPA Page Faults â†’ Offline Model)\n",
    "This notebook lets you:\n",
    "- Load a **Windows Performance Analyzer** (WPA) **Page Faults** CSV export\n",
    "- Preprocess and **bucket** virtual addresses\n",
    "- Run **baselines**: LRU working-set, Stride, Markov-1, Markov-2\n",
    "- Evaluate **prefetch** decisions with a time/fault horizon and cache budget\n",
    "- (Optional) Compare with a lightweight **ML classifier** if `scikit-learn` is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864531c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, math, json, random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter, deque\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "CSV_PATH = r\"/mnt/data/data.csv - Sheet1.csv\"\n",
    "PROCESS_NAME_FILTER = \"chrome\"  # set None for system-wide\n",
    "BUCKET_SIZE = 65536\n",
    "\n",
    "PREFETCH_K = 1\n",
    "HORIZON_EVENTS = 10\n",
    "CACHE_PAGES = 32768\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1731af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load CSV ---\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "\n",
    "col_map = {\n",
    "    'Log Time (s)': 'LogTimeSec',\n",
    "    'ByteCount': 'Bytes',\n",
    "    'Thread ID': 'TID',\n",
    "    'Virtual Address': 'VirtualAddress',\n",
    "}\n",
    "for k, v in col_map.items():\n",
    "    if k in df_raw.columns:\n",
    "        df_raw.rename(columns={k: v}, inplace=True)\n",
    "\n",
    "df = df_raw.dropna(subset=['Process']).copy()\n",
    "\n",
    "def split_proc(s: str):\n",
    "    m = re.match(r'^(.*)\\s+\\((\\d+)\\)$', str(s).strip())\n",
    "    if m:\n",
    "        return m.group(1).strip(), int(m.group(2))\n",
    "    return s.strip(), np.nan\n",
    "\n",
    "pinfo = df['Process'].apply(split_proc)\n",
    "df['ProcessName'] = pinfo.map(lambda x: x[0])\n",
    "df['PID'] = pinfo.map(lambda x: x[1]).astype('Int64')\n",
    "\n",
    "for c in ['LogTimeSec', 'Bytes', 'Count']:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "if PROCESS_NAME_FILTER:\n",
    "    mask = df['ProcessName'].str.lower().str.contains(PROCESS_NAME_FILTER.lower(), na=False)\n",
    "    df = df[mask].copy()\n",
    "\n",
    "df = df.dropna(subset=['LogTimeSec', 'VirtualAddress']).copy()\n",
    "\n",
    "def parse_va(v):\n",
    "    s = str(v).strip()\n",
    "    try:\n",
    "        if s.lower().startswith('0x'):\n",
    "            return int(s, 16)\n",
    "        return int(s, 16)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return int(float(s))\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "df['VA'] = df['VirtualAddress'].apply(parse_va)\n",
    "df = df.dropna(subset=['VA']).copy()\n",
    "df['VA'] = df['VA'].astype('int64')\n",
    "\n",
    "df['PageID'] = (df['VA'] // 4096).astype('int64')\n",
    "df['BucketID'] = (df['VA'] // BUCKET_SIZE).astype('int64')\n",
    "\n",
    "df = df.sort_values(['PID', 'LogTimeSec']).reset_index(drop=True)\n",
    "\n",
    "print(\"Rows:\", len(df), \"Processes:\", df['PID'].nunique())\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Build sequences per PID ---\n",
    "sequences = {}\n",
    "for pid, grp in df.groupby('PID'):\n",
    "    seq = list(zip(grp['LogTimeSec'].to_numpy(), grp['BucketID'].to_numpy()))\n",
    "    if len(seq) >= 3:\n",
    "        sequences[int(pid)] = seq\n",
    "\n",
    "len(sequences), list(sequences.keys())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Evaluation Utilities ---\n",
    "from typing import List, Tuple, Dict\n",
    "class PrefetchSimulator:\n",
    "    def __init__(self, sequences: Dict[int, List[tuple]], cache_pages=32768, horizon_events=10):\n",
    "        self.sequences = sequences\n",
    "        self.cache_pages = cache_pages\n",
    "        self.horizon_events = horizon_events\n",
    "\n",
    "    def evaluate(self, policy_fn, prefetch_k=1, name=\"policy\"):\n",
    "        results = []\n",
    "        for pid, seq in self.sequences.items():\n",
    "            cache = deque(maxlen=self.cache_pages)\n",
    "            cache_set = set()\n",
    "            preds = hits = faults = overfetch = 0\n",
    "            buckets = [b for _, b in seq]\n",
    "\n",
    "            for i, b in enumerate(buckets):\n",
    "                faults += 1\n",
    "                if b not in cache_set:\n",
    "                    if len(cache) == cache.maxlen and cache:\n",
    "                        ev = cache.popleft()\n",
    "                        cache_set.discard(ev)\n",
    "                    cache.append(b); cache_set.add(b)\n",
    "                else:\n",
    "                    cache.remove(b); cache.append(b)\n",
    "\n",
    "                ctx = {'pid': pid, 'i': i, 'seq': buckets, 'horizon_events': self.horizon_events}\n",
    "                cand = policy_fn(ctx) or []\n",
    "                cand = list(cand)[:prefetch_k]\n",
    "\n",
    "                if cand:\n",
    "                    preds += len(cand)\n",
    "                    for c in cand:\n",
    "                        if c not in cache_set:\n",
    "                            if len(cache) == cache.maxlen and cache:\n",
    "                                ev = cache.popleft(); cache_set.discard(ev)\n",
    "                            cache.append(c); cache_set.add(c)\n",
    "                        overfetch += 1\n",
    "\n",
    "                    horizon_end = min(len(buckets), i + 1 + self.horizon_events)\n",
    "                    fut = set(buckets[i+1:horizon_end])\n",
    "                    if any(c in fut for c in cand):\n",
    "                        hits += 1\n",
    "\n",
    "            results.append({'PID': pid, 'Faults': faults, 'Prefetches': preds, 'PrefetchHits': hits,\n",
    "                            'PrefetchPrecision': (hits/preds) if preds else 0.0,\n",
    "                            'FaultHitRate': (hits/faults) if faults else 0.0,\n",
    "                            'Overfetch': overfetch})\n",
    "        out = pd.DataFrame(results); out['Policy'] = name; return out\n",
    "\n",
    "def plot_bar(df_summary, metric, title):\n",
    "    plt.figure()\n",
    "    g = df_summary.groupby('Policy')[metric].mean().reset_index()\n",
    "    plt.bar(range(len(g)), g[metric].values)\n",
    "    plt.xticks(range(len(g)), g['Policy'].tolist(), rotation=0, ha='center')\n",
    "    plt.title(title); plt.ylabel(metric); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Policies ---\n",
    "def policy_none(ctx):\n",
    "    return []\n",
    "\n",
    "def policy_stride(ctx):\n",
    "    i = ctx['i']; seq = ctx['seq']\n",
    "    if i < 2: return []\n",
    "    last, prev = seq[i], seq[i-1]\n",
    "    stride = last - prev\n",
    "    prev2 = seq[i-2]\n",
    "    stride2 = prev - prev2\n",
    "    if stride == stride2 and stride != 0:\n",
    "        return [last + stride]\n",
    "    return []\n",
    "\n",
    "def build_markov(sequences, order=1):\n",
    "    models = {}\n",
    "    for pid, seq in sequences.items():\n",
    "        buckets = [b for _, b in seq]\n",
    "        if len(buckets) <= order: continue\n",
    "        counts = defaultdict(Counter)\n",
    "        for i in range(order, len(buckets)):\n",
    "            key = tuple(buckets[i-order:i])\n",
    "            nxt = buckets[i]\n",
    "            counts[key][nxt] += 1\n",
    "        best = {k: v.most_common(1)[0][0] for k, v in counts.items() if v}\n",
    "        models[pid] = best\n",
    "    return models\n",
    "\n",
    "mk1 = build_markov(sequences, order=1)\n",
    "mk2 = build_markov(sequences, order=2)\n",
    "\n",
    "def policy_markov1(ctx):\n",
    "    pid = ctx['pid']; i = ctx['i']; seq = ctx['seq']\n",
    "    if i < 1 or pid not in mk1: return []\n",
    "    key = (seq[i],)\n",
    "    pred = mk1[pid].get(key)\n",
    "    return [pred] if pred is not None else []\n",
    "\n",
    "def policy_markov2(ctx):\n",
    "    pid = ctx['pid']; i = ctx['i']; seq = ctx['seq']\n",
    "    if i < 2 or pid not in mk2: return []\n",
    "    key = (seq[i-1], seq[i])\n",
    "    pred = mk2[pid].get(key)\n",
    "    return [pred] if pred is not None else []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c605d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Optional ML (scikit-learn) ---\n",
    "try:\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.feature_extraction import FeatureHasher\n",
    "    SKLEARN_OK = True\n",
    "except Exception as e:\n",
    "    SKLEARN_OK = False\n",
    "    print(\"scikit-learn not available; skipping ML section. Error:\", e)\n",
    "\n",
    "ML_LAST_M = 3\n",
    "ML_CLASSES_LIMIT = 5000\n",
    "\n",
    "def train_ml_models(sequences):\n",
    "    if not SKLEARN_OK: return {}\n",
    "    models = {}\n",
    "    hasher = FeatureHasher(n_features=4096, input_type='string')\n",
    "    for pid, seq in sequences.items():\n",
    "        buckets = [b for _, b in seq]\n",
    "        if len(buckets) <= ML_LAST_M + 1: continue\n",
    "        counts = Counter(buckets)\n",
    "        top_classes = set([b for b, _ in counts.most_common(ML_CLASSES_LIMIT)])\n",
    "\n",
    "        X_raw, y = [], []\n",
    "        for i in range(ML_LAST_M, len(buckets)-1):\n",
    "            ctx = buckets[i-ML_LAST_M:i]\n",
    "            nxt = buckets[i]\n",
    "            if nxt not in top_classes: continue\n",
    "            feats = [f\"b={ctx[j]}@{j}\" for j in range(len(ctx))]\n",
    "            X_raw.append(feats); y.append(nxt)\n",
    "\n",
    "        if not X_raw: continue\n",
    "        X = hasher.transform(X_raw)\n",
    "        clf = SGDClassifier(loss='log_loss', max_iter=1000, random_state=42)\n",
    "        clf.fit(X, y)\n",
    "        models[pid] = (clf, hasher, top_classes)\n",
    "    return models\n",
    "\n",
    "ml_models = train_ml_models(sequences)\n",
    "\n",
    "def policy_ml(ctx):\n",
    "    if not SKLEARN_OK: return []\n",
    "    pid = ctx['pid']; i = ctx['i']; seq = ctx['seq']\n",
    "    tup = ml_models.get(pid)\n",
    "    if not tup or i < ML_LAST_M: return []\n",
    "    clf, hasher, top_classes = tup\n",
    "    ctx_b = seq[i-ML_LAST_M+1:i+1]\n",
    "    feats = [f\"b={ctx_b[j]}@{j}\" for j in range(len(ctx_b))]\n",
    "    X = hasher.transform([feats])\n",
    "    try:\n",
    "        pred = clf.predict(X)[0]\n",
    "        if pred in top_classes:\n",
    "            return [int(pred)]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Run Evaluations ---\n",
    "sim = PrefetchSimulator(sequences, cache_pages=CACHE_PAGES, horizon_events=HORIZON_EVENTS)\n",
    "\n",
    "res = []\n",
    "res.append(sim.evaluate(policy_none, name=\"None\", prefetch_k=PREFETCH_K))\n",
    "res.append(sim.evaluate(policy_stride, name=\"Stride\", prefetch_k=PREFETCH_K))\n",
    "res.append(sim.evaluate(policy_markov1, name=\"Markov-1\", prefetch_k=PREFETCH_K))\n",
    "res.append(sim.evaluate(policy_markov2, name=\"Markov-2\", prefetch_k=PREFETCH_K))\n",
    "if 'ml_models' in globals() and ml_models:\n",
    "    res.append(sim.evaluate(policy_ml, name=\"ML-Hashed@SGD\", prefetch_k=PREFETCH_K))\n",
    "\n",
    "summary = pd.concat(res, ignore_index=True)\n",
    "summary.sort_values(['Policy', 'PID'], inplace=True)\n",
    "summary.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Aggregate metrics and plots ---\n",
    "agg = (summary.groupby('Policy', as_index=False)\n",
    "                .agg({'Faults':'sum','Prefetches':'sum','PrefetchHits':'sum'}))\n",
    "agg['PrefetchPrecision'] = agg['PrefetchHits'] / agg['Prefetches'].replace(0, np.nan)\n",
    "agg['FaultHitRate'] = agg['PrefetchHits'] / agg['Faults'].replace(0, np.nan)\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_bar(summary, 'PrefetchPrecision', 'Prefetch Precision (avg across PIDs)')\n",
    "plot_bar(summary, 'FaultHitRate', 'Fault Hit Rate (avg across PIDs)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Save CSVs ---\n",
    "out_dir = Path('/mnt/data')\n",
    "summary_path = out_dir / 'prefetch_results_per_pid.csv'\n",
    "agg_path = out_dir / 'prefetch_results_aggregate.csv'\n",
    "summary.to_csv(summary_path, index=False)\n",
    "agg.to_csv(agg_path, index=False)\n",
    "print(\"Saved:\", summary_path, agg_path)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
